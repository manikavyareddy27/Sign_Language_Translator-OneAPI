{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from itertools import product\n",
    "from my_functions import *\n",
    "import keyboard\n",
    "from tensorflow import keras\n",
    "\n",
    "actions = np.array(['a', 'b'])\n",
    "sequences = 30\n",
    "frames = 10\n",
    "\n",
    "PATH = os.path.join('data')\n",
    "\n",
    "for action, sequence in product(actions, range(sequences)):\n",
    "    try:\n",
    "        os.makedirs(os.path.join(PATH, action, str(sequence)))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot access camera.\")\n",
    "    exit()\n",
    "\n",
    "with mp.solutions.holistic.Holistic(min_detection_confidence=0.75, min_tracking_confidence=0.75) as holistic:\n",
    "    for action, sequence, frame in product(actions, range(sequences), range(frames)):\n",
    "        if frame == 0: \n",
    "            while True:\n",
    "                if keyboard.is_pressed(' '):\n",
    "                    break\n",
    "                _, image = cap.read()\n",
    "\n",
    "                results = image_process(image, holistic)\n",
    "                draw_landmarks(image, results)\n",
    "\n",
    "                cv2.putText(image, 'Recroding data for the \"{}\". Sequence number {}.'.format(action, sequence),\n",
    "                            (20,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Pause.', (20,400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Press \"Space\" when you are ready.', (20,450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "                cv2.imshow('Camera', image)\n",
    "                cv2.waitKey(1)\n",
    "\n",
    "                if cv2.getWindowProperty('Camera',cv2.WND_PROP_VISIBLE) < 1:\n",
    "                    break\n",
    "        else:\n",
    "            _, image = cap.read()\n",
    "            results = image_process(image, holistic)\n",
    "            draw_landmarks(image, results)\n",
    "\n",
    "            cv2.putText(image, 'Recroding data for the \"{}\". Sequence number {}.'.format(action, sequence),\n",
    "                        (20,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "            cv2.imshow('Camera', image)\n",
    "            cv2.waitKey(1)\n",
    "        \n",
    "        if cv2.getWindowProperty('Camera',cv2.WND_PROP_VISIBLE) < 1:\n",
    "             break\n",
    "\n",
    "        keypoints = keypoint_extraction(results)\n",
    "        frame_path = os.path.join(PATH, action, str(sequence), str(frame))\n",
    "        np.save(frame_path, keypoints)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MY FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp.solutions.drawing_utils.draw_landmarks(image, results.left_hand_landmarks, mp.solutions.holistic.HAND_CONNECTIONS)\n",
    "    mp.solutions.drawing_utils.draw_landmarks(image, results.right_hand_landmarks, mp.solutions.holistic.HAND_CONNECTIONS)\n",
    "\n",
    "def image_process(image, model):\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return results\n",
    "\n",
    "def keypoint_extraction(results):\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(63)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(63)\n",
    "    return np.concatenate([lh, rh])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 69s 242ms/step - loss: 0.6911 - categorical_accuracy: 0.7222\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.6853 - categorical_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6787 - categorical_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6676 - categorical_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6557 - categorical_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6340 - categorical_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6095 - categorical_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5834 - categorical_accuracy: 0.5926\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.5712 - categorical_accuracy: 0.7037\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5685 - categorical_accuracy: 0.7037\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5582 - categorical_accuracy: 0.7037\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.5444 - categorical_accuracy: 0.7037\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.5343 - categorical_accuracy: 0.7037\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.5339 - categorical_accuracy: 0.7037\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.5299 - categorical_accuracy: 0.7037\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 0.5235 - categorical_accuracy: 0.7037\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 280ms/step - loss: 0.5152 - categorical_accuracy: 0.7222\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 263ms/step - loss: 0.5110 - categorical_accuracy: 0.7222\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.5075 - categorical_accuracy: 0.7222\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.5020 - categorical_accuracy: 0.7407\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.4968 - categorical_accuracy: 0.7593\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 284ms/step - loss: 0.4920 - categorical_accuracy: 0.7593\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.4887 - categorical_accuracy: 0.7593\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4853 - categorical_accuracy: 0.7593\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.4785 - categorical_accuracy: 0.7593\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.4710 - categorical_accuracy: 0.7593\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.4640 - categorical_accuracy: 0.7593\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.4586 - categorical_accuracy: 0.7593\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4539 - categorical_accuracy: 0.7593\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.8241 - categorical_accuracy: 0.7407\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.4504 - categorical_accuracy: 0.7593\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4526 - categorical_accuracy: 0.7593\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 265ms/step - loss: 1.5359 - categorical_accuracy: 0.7407\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6750 - categorical_accuracy: 0.7407\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.4792 - categorical_accuracy: 0.7407\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4574 - categorical_accuracy: 0.7593\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.4592 - categorical_accuracy: 0.7593\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.4627 - categorical_accuracy: 0.7593\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.4764 - categorical_accuracy: 0.7593\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.4900 - categorical_accuracy: 0.7407\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.5038 - categorical_accuracy: 0.7407\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 0.5122 - categorical_accuracy: 0.7222\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.5150 - categorical_accuracy: 0.7222\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5118 - categorical_accuracy: 0.7222\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.5049 - categorical_accuracy: 0.7407\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.4970 - categorical_accuracy: 0.7407\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.4895 - categorical_accuracy: 0.7593\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.4833 - categorical_accuracy: 0.7593\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4765 - categorical_accuracy: 0.7593\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.4725 - categorical_accuracy: 0.7593\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.4699 - categorical_accuracy: 0.7593\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.4675 - categorical_accuracy: 0.7593\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4657 - categorical_accuracy: 0.7593\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.4651 - categorical_accuracy: 0.7593\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4639 - categorical_accuracy: 0.7593\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.4630 - categorical_accuracy: 0.7593\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4618 - categorical_accuracy: 0.7593\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.4611 - categorical_accuracy: 0.7593\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.4598 - categorical_accuracy: 0.7593\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4580 - categorical_accuracy: 0.7593\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.4569 - categorical_accuracy: 0.7593\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.4555 - categorical_accuracy: 0.7593\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.4539 - categorical_accuracy: 0.7593\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.4523 - categorical_accuracy: 0.7593\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.4515 - categorical_accuracy: 0.7593\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.4511 - categorical_accuracy: 0.7593\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.4512 - categorical_accuracy: 0.7593\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.4509 - categorical_accuracy: 0.7593\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4507 - categorical_accuracy: 0.7593\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4506 - categorical_accuracy: 0.7593\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4502 - categorical_accuracy: 0.7593\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.4497 - categorical_accuracy: 0.7593\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4494 - categorical_accuracy: 0.7593\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4484 - categorical_accuracy: 0.7593\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.4478 - categorical_accuracy: 0.7593\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.4472 - categorical_accuracy: 0.7593\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4468 - categorical_accuracy: 0.7593\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4461 - categorical_accuracy: 0.7593\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4455 - categorical_accuracy: 0.7593\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4449 - categorical_accuracy: 0.7593\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4450 - categorical_accuracy: 0.7593\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.4446 - categorical_accuracy: 0.7593\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.4444 - categorical_accuracy: 0.7593\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4443 - categorical_accuracy: 0.7593\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 9.1409 - categorical_accuracy: 0.7222\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 2.1195 - categorical_accuracy: 0.7222\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 6.8495 - categorical_accuracy: 0.6481\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4741 - categorical_accuracy: 0.7407\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.5615 - categorical_accuracy: 0.7407\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.7538 - categorical_accuracy: 0.7407\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.4489 - categorical_accuracy: 0.7593\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.4505 - categorical_accuracy: 0.7593\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.4509 - categorical_accuracy: 0.7593\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4519 - categorical_accuracy: 0.7593\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4530 - categorical_accuracy: 0.7593\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.4828 - categorical_accuracy: 0.7407\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4531 - categorical_accuracy: 0.7593\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.4531 - categorical_accuracy: 0.7593\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4529 - categorical_accuracy: 0.7593\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4526 - categorical_accuracy: 0.7593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from itertools import product\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "PATH = os.path.join('data')\n",
    "\n",
    "actions = np.array(os.listdir(PATH))\n",
    "sequences = 30\n",
    "frames = 10\n",
    "\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "\n",
    "landmarks, labels = [], []\n",
    "\n",
    "for action, sequence in product(actions, range(sequences)):\n",
    "    temp = []\n",
    "    for frame in range(frames):\n",
    "        npy = np.load(os.path.join(PATH, action, str(sequence), str(frame) + '.npy'))\n",
    "        temp.append(npy)\n",
    "    landmarks.append(temp)\n",
    "    labels.append(label_map[action])\n",
    "\n",
    "X, Y = np.array(landmarks), to_categorical(labels).astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10, random_state=34, stratify=Y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, activation='relu', input_shape=(10,126)))\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(32, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=100)\n",
    "\n",
    "model.save('my_model')\n",
    "\n",
    "predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "test_labels = np.argmax(Y_test, axis=1)\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "from my_functions import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import keyboard\n",
    "\n",
    "\n",
    "PATH = os.path.join('data')\n",
    "\n",
    "actions = np.array(os.listdir(PATH))\n",
    "\n",
    "model = load_model('my_model')\n",
    "\n",
    "sentence, keypoints = [' '], []\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot access camera.\")\n",
    "    exit()\n",
    "\n",
    "with mp.solutions.holistic.Holistic(min_detection_confidence=0.75, min_tracking_confidence=0.75) as holistic:\n",
    "    while cap.isOpened():\n",
    "        _, image = cap.read()\n",
    "        results = image_process(image, holistic)\n",
    "        draw_landmarks(image, results)\n",
    "        keypoints.append(keypoint_extraction(results))\n",
    "\n",
    "        if len(keypoints) == 10:\n",
    "            keypoints = np.array(keypoints)\n",
    "            prediction = model.predict(keypoints[np.newaxis, :, :])\n",
    "            keypoints = []\n",
    "            \n",
    "            if np.amax(prediction) > 0.9:\n",
    "                if sentence[-1] != actions[np.argmax(prediction)]:\n",
    "                    sentence.append(actions[np.argmax(prediction)])\n",
    "\n",
    "        if len(sentence) > 7:\n",
    "            sentence = sentence[-7:]\n",
    "        \n",
    "        if keyboard.is_pressed(' '):\n",
    "            sentence = [' ']\n",
    "\n",
    "        textsize = cv2.getTextSize(' '.join(sentence), cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "        text_X_coord = (image.shape[1] - textsize[0]) // 2\n",
    "            \n",
    "        cv2.putText(image, ' '.join(sentence), (text_X_coord, 470), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Camera', image)\n",
    "        \n",
    "        cv2.waitKey(1)\n",
    "        if cv2.getWindowProperty('Camera',cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
